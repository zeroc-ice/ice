name: "Publish MISC Packages"
# This workflow publishes various packages (MSI, MATLAB, XCFramework, Swift, Brew) to S3.
# We use a single workflow to avoid exceeding the reusable workflow limit in GitHub Actions.

on:
  workflow_dispatch:
    inputs:
      channel:
        description: "The channel to publish to (e.g., 3.8, nightly)"
        required: true
      run_id:
        description: "The run ID to use for downloading artifacts"
        required: true
  workflow_call:
    inputs:
      channel:
        required: true
        type: string
      run_id:
        required: true
        type: string

jobs:
  publish-msi-packages:
    name: "Publish MSI Packages"
    runs-on: "ubuntu-24.04"
    steps:
      - name: Download MSI artifacts
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          RUN_ID: ${{ inputs.run_id }}
        run: |
          set -euo pipefail
          mkdir -p staging
          gh run download "$RUN_ID" --repo zeroc-ice/ice --pattern "windows-msi" --dir staging

      - name: Publish MSI Packages
        run: |
          set -euo pipefail
          if [ "${CHANNEL}" = "nightly" ]; then
            # Rename the MSI file to Ice-nightly.msi if it's the nightly channel
            aws s3 cp staging/windows-msi/*.msi "s3://zeroc-downloads/ice/${CHANNEL}/Ice-nightly.msi"
          else
            aws s3 cp staging/windows-msi/*.msi "s3://zeroc-downloads/ice/${CHANNEL}/"
          fi

        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          CHANNEL: ${{ inputs.channel }}

  publish-matlab-packages:
    name: "Publish MATLAB Packages"
    runs-on: "ubuntu-24.04"
    steps:
      - name: Download MATLAB artifacts
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          RUN_ID: ${{ inputs.run_id }}
        run: |
          set -euo pipefail
          mkdir -p staging
          gh run download "$RUN_ID" --repo zeroc-ice/ice --pattern "matlab-packages-*" --dir staging

      - name: Publish MATLAB Packages
        run: |
          set -euo pipefail
          if [ "${CHANNEL}" = "nightly" ]; then
            # Rename the Toolbox files to ice-nightly-R2025a-<os>.mltbx if it's the nightly channel
            aws s3 cp staging/matlab-packages-windows-*/ice-*-R2025a-win.mltbx "s3://zeroc-downloads/ice/${CHANNEL}/ice-nightly-R2025a-win.mltbx"
            aws s3 cp staging/matlab-packages-ubuntu-*/ice-*-R2025a-linux.mltbx "s3://zeroc-downloads/ice/${CHANNEL}/ice-nightly-R2025a-linux.mltbx"
          else
            aws s3 cp staging/matlab-packages-windows-*/ice-*-win.mltbx "s3://zeroc-downloads/ice/${CHANNEL}/"
            aws s3 cp staging/matlab-packages-ubuntu-*/ice-*-linux.mltbx "s3://zeroc-downloads/ice/${CHANNEL}/"
          fi
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          CHANNEL: ${{ inputs.channel }}

  publish-xcframework-packages:
    name: "Publish XCFramework Packages"
    runs-on: "ubuntu-24.04"
    steps:
      - name: Download XCFramework artifacts
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          RUN_ID: ${{ inputs.run_id }}
        run: |
          set -euo pipefail
          mkdir -p staging
          gh run download "$RUN_ID" --repo zeroc-ice/ice --pattern "xcframework-packages" --dir staging

      - name: Publish XCFramework Packages
        run: |
          set -euo pipefail
          mkdir -p "${CHANNEL}"
          # Copy all .zip files from staging/xcframework-packages to the channel directory
          # Preserve file attributes; do not overwrite existing files.
          cp -npv staging/xcframework-packages/*.zip "${CHANNEL}/"
          aws s3 sync "${CHANNEL}/" "s3://zeroc-downloads/ice/${CHANNEL}/" --exclude "*" --include "*.zip"
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          CHANNEL: ${{ inputs.channel }}

  publish-swift-packages:
    name: "Publish Swift Packages"
    runs-on: macos-15
    # Stable Swift releases must be published manually.
    if: ${{ inputs.channel == 'nightly' }}
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Download XCFramework artifacts
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          RUN_ID: ${{ inputs.run_id }}
        run: |
          set -euo pipefail
          mkdir -p staging
          gh run download "$RUN_ID" --repo zeroc-ice/ice --pattern "xcframework-packages" --dir staging

      - name: Create ice-swift repository
        run: ./update-ice-swift-nightly.sh
        working-directory: packaging/swift
        env:
          ICE_NIGHTLY_PUBLISH_TOKEN: ${{ secrets.ICE_NIGHTLY_PUBLISH_TOKEN }}
          STAGING_DIR: ${{ github.workspace }}/staging/xcframework-packages
        if: ${{ inputs.channel == 'nightly' }}

  publish-brew-packages:
    name: "Publish Brew Packages"
    runs-on: macos-15
    # Stable Brew releases must be published manually.
    if: ${{ inputs.channel == 'nightly' }}
    env:
      CHANNEL: ${{ inputs.channel }}
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Download Homebrew Bottle XCFramework artifacts
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          RUN_ID: ${{ inputs.run_id }}
        run: |
          set -euo pipefail
          mkdir -p staging
          gh run download "$RUN_ID" --repo zeroc-ice/ice --pattern "homebrew-bottle" --dir staging

      - name: Publish Homebrew Bottle Packages
        run: |
          set -euo pipefail
          mkdir -p "${CHANNEL}"
          # Copy all .tar.gz files from staging/homebrew-bottle to the channel directory
          # Preserve file attributes; do not overwrite existing files.
          cp -npv staging/homebrew-bottle/*.tar.gz "${CHANNEL}/"
          aws s3 sync "${CHANNEL}/" "s3://zeroc-downloads/ice/${CHANNEL}/" --exclude "*" --include "*.tar.gz"
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
